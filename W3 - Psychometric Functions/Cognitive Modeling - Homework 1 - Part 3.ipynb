{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cognitive Modeling (02458): Homework 1 - Part 3: Psychometric Functions\n",
    "\n",
    "---\n",
    "\n",
    "_By Sebastian Sbirna (s190553) and Aleksander Frese (s163859)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psychometric function - parameter computation\n",
    "\n",
    "In this experiment, we have a psychometric function shaped in the form of a Gaussian CDF. We are given the stimulus levels and number of yes responses for each level, from a total of 50 different trials performed for each stimulus in part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trial_no = 50\n",
    "\n",
    "stim_levels = [0.4, 0.9, 1.2, 1.7, 2.3]\n",
    "yes_resp_no = [1, 6, 13, 32, 49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are asked to estimate the parameters of the psychometric function. Since this function is represented as a CDF, we may inverse the CDF function in order to retrieve the probability density function of our experiment.\n",
    "Knowing this, and ___noting the stimulus values as x___, we can write the psychometric function which is a expresses the response of the observer as:\n",
    "\n",
    "$$ \\phi[P(yes|x)]^{-1} = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "The two unknown parameters are $\\mu$ and $\\sigma$, however they can be computed if we bring the psychometric equation to a linear form:\n",
    "\n",
    "$$ \\phi[P(yes|x)]^{-1} = \\frac{1}{\\sigma}x + (-\\frac{\\mu}{\\sigma})$$\n",
    "\n",
    "The equation is now written in the form $y = ax + b$, with x (_stimulus_) being known and y (_inverse of probabilities of responder saying yes for the different stimulus trials_) being computable. Using this, we will compute $a = \\frac{1}{\\sigma}$ and $b = -\\frac{\\mu}{\\sigma}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will compute the probabilities $P(Yes|stimulus)$, and after that, we will compute the inverse CDF of these probabilities, so that we have the whole range of values for our _y_ in the linear equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02 0.12 0.26 0.64 0.98]\n"
     ]
    }
   ],
   "source": [
    "p_yes = np.array(yes_resp_no) / total_trial_no\n",
    "print(p_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.05374891 -1.17498679 -0.64334541  0.35845879  2.05374891]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "Y = stats.norm.ppf(p_yes)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will compute the parameters $\\mu$ and $\\sigma$, using the matrix $Y$ which contains the values for the inverse CDF of the probability of 'yes' responses by observers, and the matrix $X$ with two columns representing, first, a column of values for the original stimulus and also a column of ones for the computation of the intercept (_b_), since the intercept value is always constant across our model. We will want to compute the matrix $\\beta$, where we understand that $ \\beta= \\left[ {\\begin{array}{c} slope(a) \\\\ intercept(b) \\\\ \\end{array} } \\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the computation of finding $\\beta$ from the formula $Y = X * \\beta$, we will use the pseudoinverse of the matrix $X$, i.e. $X^{-1}$. \n",
    "\n",
    "Therefore: $X^{-1} * Y (= X^{-1} * X * \\beta) = \\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4 1. ]\n",
      " [0.9 1. ]\n",
      " [1.2 1. ]\n",
      " [1.7 1. ]\n",
      " [2.3 1. ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((np.array(stim_levels).reshape(5,1), np.ones((5, 1))), axis = 1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pseudoinverse of the matrix $X$ may be obtained in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42056075, -0.18691589, -0.04672897,  0.18691589,  0.46728972],\n",
       "       [ 0.74672897,  0.44299065,  0.26074766, -0.04299065, -0.40747664]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.pinv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By multiplying the pseudoinverse of X ($X^{-1}$) with the matrix Y, we may obtain the matrix $\\beta$ and the results for the slope $a$ and the intercept $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.14011014, -3.07411787])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = np.dot(np.linalg.pinv(X), Y)\n",
    "np.dot(np.linalg.pinv(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now have found $a$, we have simultaneously found $\\sigma$. \n",
    "\n",
    "To compute $\\mu$, we just need to plug in $\\sigma$ into the equation for $b$ (whose value has just been found from the $\\beta$ matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46726567019117615\n"
     ]
    }
   ],
   "source": [
    "sigma = 1/a\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4364297449222871\n"
     ]
    }
   ],
   "source": [
    "mu = b * -sigma\n",
    "print(str(mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this thought process, we have computed the $\\mu = 1.43$ and $\\sigma = 0.46$ values of the psychometric function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psychometric function - sensitivity ($d'$) computation\n",
    "\n",
    "Now, a follow-up experiment decides to only use 2 values for initial stimulus: _x = 1_ and _x = 2_. The observer can also respond in only two methods: 'high' (_which has the same meaning as 'yes' previously_) or 'low'. We are asked to compute the sensitivity ($d'$) of the observer. \n",
    "\n",
    "The sensitivity of this observer refers to distance between the gaussian PDF of the stimulus of high intensity (centered around the mean $\\mu_s = 2$) and the gaussian PDF of the stimulus of low intensity (centered around the mean $\\mu_s = 1$).\n",
    "\n",
    "This can be computed in two ways:\n",
    "1. We can use the formula for the sensitivity $d'$ of the equal variance observer, namely: $d' = \\phi^{-1}(P(Hit)) - \\phi^{-1}(P(FA))$. \n",
    "\n",
    "This can be computed using the values of __P(Hit)__ and __P(FA)__ from the psychometric function. \n",
    "\n",
    "Even though we do not have actual data regarding the number of 'high' responses in the experiment, we can compute that using our linear equation and the values for $\\mu$ and $\\sigma$, computed just earlier.\n",
    "What you would get from the equation would be $$\\phi^{-1}(P(High|x = 2)) = \\phi^{-1}(P(Hit))$$ and $$\\phi^{-1}(P(High|x = 1)) = \\phi^{-1}(P(FA))$$, when plugging in x = 1 and x = 2, respectively, into the linear function.\n",
    "\n",
    "There is, however, a more simple method.\n",
    "\n",
    "2. We can standardize the difference between the two stimuli (_since the stimulus value corresponds to the mean of its corresponding PDF_) by the standard deviation of the psychometric function. The std $\\sigma$ has just been computed above as a parameter to our model.\n",
    "\n",
    "Therefore: $$d' = \\frac{2 - 1}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1401101424610585\n"
     ]
    }
   ],
   "source": [
    "d_prime = (2 - 1)/sigma\n",
    "print(d_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show that this computation is exactly equivalent to the longer method described above, let us compute $\\phi^{-1}(P(High|x = 2))$ and $\\phi^{-1}(P(High|x = 1))$ using the linear equation from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.206102418881179\n"
     ]
    }
   ],
   "source": [
    "x_stimulus_high = 2\n",
    "inverse_p_hit = (1/sigma) * x_stimulus_high + (-mu/sigma)\n",
    "print(inverse_p_hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9340077235798794\n"
     ]
    }
   ],
   "source": [
    "x_stimulus_low = 1\n",
    "inverse_p_fa = (1/sigma) * x_stimulus_low + (-mu/sigma)\n",
    "print(inverse_p_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1401101424610585\n"
     ]
    }
   ],
   "source": [
    "d_prime = inverse_p_hit - inverse_p_fa\n",
    "print(d_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our computations, the two methods of computing $d'$ are equivalent and yield the same result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
